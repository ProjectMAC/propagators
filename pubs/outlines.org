#+STARTUP: odd
#+STARTUP: hidestars

European Lisp Symposium submission deadline: 1/29/2010
* List of partial information structures
Base Lattices:
The flat lattice
- e.g. just values; units & dimensions
Numbers (or any total order) by max or min
Integers by divisibility (lcm or gcd)
Ranges (continuous) by intersection (e.g. continuous constraints)
Ranges (continuous) by union
Sets (discrete) by intersection (e.g. discrete constraints)
Sets (discrete) by union
Informed non-knowledge
Linear-programming-style inequalities?
Symbolic expressions and inequalities; solving them

Base Posets:
Classes by inheritance
Types more generally, by containment
Logical propositions by implication
Sets by subset (e.g. justification premises)

Transformations:
Poset -> Lattice by symbolic joins
Tupling
- e.g. add units; add types; add logic
Compound (algebraic) data structures
Add provenance and TMS (boolean premises; time-stamped inputs)
Probabilistic story (premises with priors)
Continuous guesses (and symbolic algebra?)
Functions by joining in the range
Requests?

Uses:
DDB
DDB constraint satisfiers
DDB probabilistic inference
- (over constraints!)
- (evidence pushing for free?)
* General audience merging
Story: Merging is good for you.  Accumulators that merge are good for
you.  If they never forget anything that matters (= the function
commutes with merging at either end = the function is monotonic in
information) you don't have to worry about reading them too late; If
merging commutes, you don't have to worry about race conditions for
writing them; If merging is idempotent you don't have to worry about
reading them early, and the resulting repetitions and recalculations.
(And if you're really sophisticated, you can use fancy
incremental-update algorithms).

"Object design pattern for concurrency" (or for any complicated
schedule, whether concurrent or not).
* Recursion in Propagator Networks
direct copies; virtual copies; environment structures
how is this like traditional languages; how is it done in traditional languages;
* Short AI paper
summary of thesis work
- philosophy for interfaces; monotonicity of information
applicability to AI
each cell is a topic-specific blackboard
- thought is multidirectional
* Layers for the aspect oriented
Merging alleviates the "multiple layers want to smash this slot" problem
* Haskell Paper(s)
*** Partial orders generalize total orders; lattice join is your friend
See lattice type list
Joinable streams (just how useful a lattice is this?)
Every poset can be turned into a totally ordered set, but this is not
a lattice homomorphism
Lattices and Posets have products and sums, but total orders do not.
"Adjoin symbolic answers" turns any partial order into a lattice (I think).
That operation turns v&ses into tmses
*** Joinable streams are good for you
- Operations: joinify, fmap, drop_eager (optional), merge
- mappable function should commute with join for joinify to be OK.
- join should commute for merge to be OK; be idempotent for drop_eager to
  be OK after joining
- Can I reproduce FRP at this point?  Dependent FRP?
*** "Tying the knot" allows circular groups of such streams (loeb; arrows?)
Issues with the type system under loeb; do arrows solve them?
What about the quiescence detector?  Do I have to write my own job scheduler?
*** Also
More in haskell/merging.tex
Non-Eq functions suck
TMSes?  Poset turns into lattice by adding symbolic joins
Algebraic data types
* Bottom-avoiding networks via Informed Non-Knowledge
* "Provability maintenance" system (as opposed to "truth maintenance")
Just replace classical logic with intuitionistic logic.
Can I parameterize this thing completely over the logic it uses?
* Parallel generic operations
Merging alleviates the method selection problem -- if the results agree,
who cares which one was more specific?  And if you really want specificity
information, you can build a partial information structure that will 
track specificity and give the more specific result priority.

Side effects are complicated!

Traditional specificity is a screw because it prevents predicate dispatch
* Is my TMS over cons story worth telling?
* FRP with input identities but no propagators
Time is a partial order
* FRP on propagators
Cycles for free given input identity idea
* Propagators break the only real distinction between compilers and interpreters
which is that compilers are expected to do multidirectional things
like type inference, flow analysis, specification inference, etc
* Static/dynamic type checking on propagators
* Static/dynamic verified computing on propagators
* Dependency-directed constraint satisfaction on propagators
* Partial evaluation on propagators
* Probabilistic programming on propagators
* Infinitely hairy analysis-searches on propagators
