Propagators & merging allow a new means of composition
- and conversely decomposition

Since merging is more general than just production, it can be pushed
down into the very fabric and foundation of the language.

Merging and propagation are general enough to recover all programming
models: standard, logic, constraint, functional-reactive, type-system,
nondeterministic (implicit search); can go further, e.g. probabilistic
- "Static" information can be pushed around at runtime just like
  everything else; it can inform and correct the dynamic information,
  and also be informed by it (dependent types, anyone?)

Automatically concurrent.

Design the language for expressivity first and foremost; let the
compiler or runtime worry about making it run fast enough.
- Then again, this is the philosophy that killed Lisp...
- Fantastic opportunity for partial evaluation

How does this help security?  Easy to try different redundant methods,
and so defend against compromise of a method; new composition
(probably) helps defense-in-depth; concurrency should make life more
confusing for the adversary, and mitigate (at least some)
side-channels.

Should strive to implement past good ideas coherently (but as
libraries) (see ideas.org/"Great Ideas of Expressiveness"); maybe also
add some new ideas that haven't been explored as thoroughly yet.

Functions should not be entirely opaque: want to be able to do algebra
on them
- e.g. Haskell type inference gives the power of being able to
  dispatch on the type of one's continuation

----------------------------------------------------------------------

At user level, everything should be cells and propagators.  Probably,
multidirectional stories should be the defaults, although
unidirectional versions should be accessible.

I expect a variety of partial information types to be useful library
elements: the flat lattice, TMSes, type systems, constraint packages,
logic programming, FRP...

The garbage collector will be very interesting: there will be
tradeoffs between the memory needed to update a partial computation
with new information and the time needed to recompute the answer for
the updated information from scratch.  (Information monotonicity
allows the GC to forget intermediate results!)

There is a generalization of strictness analysis here: in many cases,
it should be possible to predict that an abstraction's body will
perfectly mix, say, input premises, and therefore compile the detailed
tracking thereof out of said body (improving the efficiency of the
interior).  Is there a good partial information type for pulling this
off?


Should not be necessary to say more than you need to to convey an
idea, but you should not be forced to say less than you mean.

Any "design pattern" should be expressible and nameable within the
language.

Unless required for security, all objects should be "translucent" so
as to enable reflection.  Opacity is sometimes needed, but it must be
explicitly selected. 

Additivity...
  e.g. numerical code should be augmentable with units/dimensions.
       should be generic so that extensible to work on matrices, etc.
           may violate assertions about commutativity
           such assertions should be additive.
  add premises, provenance tracking, truth maintenance, backtracking
  add symbolic real numbers and algebra

Additivity mechanisms
  definitions: add new things with new names
  generic operations
  concurrency (try-two-ways); merging supports this immensely
  layers (see below)

Minksy pattern: propagators enable and disable other (groups of)
propagators

Non-hierarchical abstraction

The principle of maximum expressivity and libertarian programming.
- This assumes that the programmers are very good, and will know when
  not to use mechanisms that enhance expressivity sometimes and impair
  it other times (as opposed the designs of more restrictive
  languages, which seem to take more of an "average case" approach to
  allowing potentially confusing constructs).
- This does not contradict the immense importance of very good defaults
  - but perhaps there could be modes of expression that say "here,
    the defaults should be different from the normal defaults".

For security, expressive libertariansim means being able to express
that some things should not be done.  But then, what happens when two
programmers, both of whose freedom of expression we want to uphold,
come into conflict?

----------------------------------------------------------------------

Layers have the property of "automagically" laying over code one has
written: the function + has operational information, and type
information, and dependency-flow information, and ...  A module should
be able to add a new layer (and have it attach properly to extant
code, that need not be further modified)

A layer may be able to do something with a compound even without
opening it (e.g. provenance, but probably not type inference).  Other
layers may need to look at the wiring diagram, or even trace each
individual execution.

It may be quite possible to compile layers by first copying the wiring
diagram of some abstraction into the layer, without inputs, and then
optimizing the machine that diagram represents (e.g. provenance does
the same thing in response to + and -, so those may be combinable in
the provenance layer even if they are not combinable in the base
layer).

Possible example layers:
- Types (and inference)
- Dependent types?
- Units and Dimensions
- Provenance (and Worldviews and Hypotheticals)
- Slices (terminal equivalence)
- Can write symbolic algebraic expressions and constraints as layers
- Differentials for automatic differentiation
- Advice
  - Logging
- Memory address register break
- Possibility sets for constraints?
- FrTime?

Maybe layers are like monads after all.  Or like monad transformers.
