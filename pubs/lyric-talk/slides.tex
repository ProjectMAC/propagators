\documentclass{beamer}

\newcommand{\wordslide}[1]{\begin{frame}\begin{center}\Huge {#1}\end{center}\end{frame}}
\newcommand{\pictureslide}[2][]{\begin{frame}\begin{center}\includegraphics[width=300pt]{{#2}}\\ \huge {{#1}}\end{center}\end{frame}}
\newcommand{\tallpictureslide}[2][]{\begin{frame}\begin{center}\includegraphics[height=180pt]{{#2}}\\ \huge {{#1}}\end{center}\end{frame}}

\newenvironment{codeslide}[1]{\begin{frame}[containsverbatim]%
\begin{center}
\huge {{#1}}
\end{center} }{\end{frame}}

\title[Probabilistic Programming]{Probabilistic Programming}
\author{Alexey Radul}
\date{February 3rd, 2010, Lyric Semiconductor}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
\begin{center}\Huge Vision\end{center}
\begin{itemize}
\item Maximally expressive probabilistic models
\pause
\item by embedding probabilistic reasoning into a maximally expressive general
programming language
\end{itemize}
\end{frame}

\wordslide{Expressiveness Demo\\ \small (and Scheme primer)}

\begin{frame}
\begin{center}\Huge Who is doing it? (1)\end{center}
\begin{thebibliography}{1}
\bibitem{prob-scheme-techreport}
Alexey Radul.
\newblock {Report on the Probabilistic Language Scheme}.
\newblock CSAIL Tech Report MIT-CSAIL-TR-2007-059, MIT Computer Science and
  Artificial Intelligence Laboratory, Cambridge, MA, 2007.
  \url{http://hdl.handle.net/1721.1/39831}.

\bibitem{kiselyov-shan-2009-embedded}
Oleg Kiselyov and Chung chien Shan.
\newblock {Embedded Probabilistic Programming}.
\newblock In Walid Taha, editor, {\em Proceedings of the working conference on
  domain-specific languages}, pages 360--384. 2009.

\end{thebibliography}
\end{frame}

\begin{frame}
\begin{center}\Huge Who is doing it? (2)\end{center}
\begin{thebibliography}{1}
\bibitem{goodman-mansinghka-2008-church}
N.D. Goodman, V.K. Mansinghka, D.~Roy, K.~Bonawitz, and J.B. Tenenbaum.
\newblock {Church: a Language for Generative Models}.
\newblock In {\em Uncertainty in Artificial Intelligence}, 2008.

\bibitem{pfeffer-2007-ibal-design-implementation}
Avi Pfeffer.
\newblock {The Design and Implementation of IBAL: A General-Purpose
  Probabilistic Language}.
\newblock In {\em An Introduction to Statistical Relational Learning}, pages
  399--432. MIT Press, Cambridge, MA, 2007.

\end{thebibliography}
\end{frame}

\begin{frame}
\begin{center}\Huge Probabilistic Scheme\end{center}
\begin{itemize}
\item Embedded
\item in Scheme
\item with continuation capture
\item inferring by depth-first search
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge Kiselyov and Shan's System\end{center}
\begin{itemize}
\item Embedded
\item in OCaml
\item with delimited continuations
\item inferring by search or sampling
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge Church\end{center}
\begin{itemize}
\item Standalone
\item pure functional
\item in the Lisp family
\item inferring by Metropolis-Hastings over execution traces
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge IBAL\end{center}
\begin{itemize}
\item Standalone
\item pure functional
\item in the ML family
\item inferring by compilation to a micro-factor graph
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge Dilemma\end{center}
\begin{itemize}
\item Embedded languages get a high-quality implementation of the
  deterministic parts for free % Say ``tree''
\item Standalone languages get inspection into the structure of the
  model, which helps inference % Say ``graph''
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge My Research\end{center}
\begin{itemize}
\item New computation model based on propagation of information around a graph
\item General enough to support embedded probabilistic inference that
  can use the graph structure of a program
\end{itemize}
\end{frame}

\begin{frame}
\begin{center}\Huge Contributions\end{center}
\begin{itemize}
\item Embedding of probabilistic reasoning into Scheme
\item Propagator network infrastructure for efficient non-sequential
  computing, including inference
\end{itemize}
\end{frame}

\end{document}
